<h1> SignLanguageDetection-With-Voice </h1> 

<h4>
  
  Sign language detection with voice output is a technology that combines computer vision and natural language processing to translate sign language gestures into spoken words.
  
</h4>

<h4>
  
1. **Gesture Recognition**:
      Using cameras and advanced algorithms, the system captures and analyzes the hand movements and gestures of a person using sign language. Machine learning models, often trained on large datasets of sign language gestures, are employed to accurately identify these gestures in real-time.

2. **Text Conversion**:
      Once a gesture is recognized, it is mapped to its corresponding word or phrase. This mapping is displayed as text on a screen, providing a visual confirmation of the detected sign.

3. **Voice Output**:
      Simultaneously, the recognized word or phrase is converted into speech using text-to-speech (TTS) technology. This allows the system to vocalize the recognized sign, facilitating communication with people who may not understand sign language.

This technology has significant potential to enhance communication for the deaf and hard-of-hearing community, bridging the gap between sign language users and those who do not know sign language.

</h4>

<h1> Procedure </h1>

<h4>
  
* Install the required packages

* There are many files to create, display, generate and to recognise. If you want to run all, you can proceed

* If you just want to recongnise only the gestures, run fun_util.py

* use "python fun_util.py" this command to run the file and see the gestures along with the voice

</h4>

<h1> Screenshots </h1>

1.
   <p align = "Center" >
  <img src = "https://github.com/AashikaShravani/SignLanguageDetection-With-Voice/assets/140937457/b7e7013a-4aba-4437-a3c9-21f38bb64920" >
   </p>

2.
  <p align = "Center" >
    <img src = "https://github.com/AashikaShravani/SignLanguageDetection-With-Voice/assets/140937457/ff3d4f34-7e4f-49c9-9e94-391755481cb4" >
  </p>  
